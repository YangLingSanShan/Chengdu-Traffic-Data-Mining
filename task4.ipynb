{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下一跳预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path, output_path):\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 1. 将时间time转为基于最早时间的偏移time_offset\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    base_time = df['time'].min()\n",
    "    df['time_offset'] = (df['time'] - base_time).dt.total_seconds()\n",
    "\n",
    "    # 2. 将coordinates列转换为经度和纬度两列\n",
    "    df[['longitude', 'latitude']] = df['coordinates'].apply(lambda x: eval(x) if pd.notna(x) else [None, None]).tolist()\n",
    "\n",
    "    df['holiday'] = df['time'].apply(lambda x: 1 if (x.month == 10 and 1 <= x.day <= 7) else 0)\n",
    "\n",
    "    weather_df = pd.read_csv('./data/weather.csv')\n",
    "\n",
    "    # 确保日期格式一致\n",
    "    weather_df['Date'] = pd.to_datetime(weather_df['Date'])\n",
    "    df['date'] = df['time'].dt.date\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # 合并轨迹数据和天气数据\n",
    "    df = pd.merge(df, weather_df, left_on='date', right_on='Date', how='left')\n",
    "\n",
    "    # 删除不需要的列\n",
    "    df.drop(columns=['Date','Day','date'], inplace=True)\n",
    "\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    # 保存处理后的数据\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "process_data('./data/traj.csv', './product_data/task4_train_data.csv')\n",
    "process_data('./data/jump_task.csv', './product_data/task4_todo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 114514\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiLSTMPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bi-LSTM 需要两个隐藏状态\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(2, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel(config)\n",
    "\n",
    "class BertPredictor(nn.Module):\n",
    "    def __init__(self, pretrained_model, output_dim, input_dim=2, embedding_dim=768):\n",
    "        super(BertPredictor, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embedding_dim)  # 输入维度为2（[x, y]）\n",
    "\n",
    "        self.encoder = pretrained_model\n",
    "        self.fc = nn.Linear(self.encoder.config.hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        outputs = self.encoder(inputs_embeds=embedded).last_hidden_state\n",
    "        prediction = self.fc(outputs[:, -1, :])  \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSequence(df, features, window_size):\n",
    "    # 找到轨迹长度 >= 15的所有轨迹\n",
    "    traj_index_list = df.groupby(['trajectory_id']).size()        # Series\n",
    "    traj_index_list = traj_index_list[traj_index_list > 15]\n",
    "\n",
    "    # 按照滑动窗口进行划分\n",
    "    seq = []\n",
    "    label = []\n",
    "    for index, _ in traj_index_list.items():\n",
    "        trajectory_id = index\n",
    "        trajectory = df[(df['trajectory_id'] == trajectory_id)][features].values.tolist()\n",
    "        num_splits = len(trajectory) - window_size + 1\n",
    "        for i in range(num_splits):\n",
    "            seq.append(trajectory[i:i + window_size - 1])\n",
    "            label.append(trajectory[i + window_size - 1])\n",
    "    seq = torch.tensor(np.array(seq), dtype=torch.float32).to(device)\n",
    "    label = torch.tensor(np.array(label), dtype=torch.float32).to(device)\n",
    "    return seq, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmse(predictions, targets):\n",
    "    mse = torch.mean((predictions[:, :3] - targets[:, :3]) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(train_X, train_Y, val_X, val_Y, model,\n",
    "               lr=1e-2, epoch_num=20, logging_steps=5):\n",
    "    # 使用 DataLoader 和 TensorDataset 批量加载数据\n",
    "    train_set = TensorDataset(train_X, train_Y)\n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True, generator=torch.Generator(device=device))\n",
    "    test_set = TensorDataset(val_X, val_Y)\n",
    "    test_loader = DataLoader(test_set, batch_size=32, shuffle=False, generator=torch.Generator(device=device))\n",
    "\n",
    "    # 初始化损失函数和优化器\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # 模型训练\n",
    "    for epoch in tqdm(range(epoch_num)):\n",
    "        loss = 0.0\n",
    "        index = 0\n",
    "        for data in train_loader:\n",
    "            \n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if index % 150 == 0:\n",
    "                print(f\"iter: {index}\")\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += loss.item()\n",
    "            index += 1\n",
    "            \n",
    "        # log\n",
    "        if epoch % logging_steps == (logging_steps - 1):\n",
    "            print(f\"Epoch {epoch + 1}, loss: {loss / len(train_loader):.6f}\")\n",
    "\n",
    "    # 用验证集评估\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            preds.append(outputs)\n",
    "    \n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    loss = criterion(preds, val_Y)\n",
    "    rmse = calc_rmse(preds, val_Y)\n",
    "\n",
    "    return model, loss.item(), rmse.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部特征组合\n",
    "all_features = [\n",
    "    ['longitude', 'latitude', 'holiday', 'High Temp', 'Low Temp', 'Rain', 'Wind Force'],\n",
    "    ['longitude', 'latitude'],\n",
    "]\n",
    "\n",
    "# 全部可选模型\n",
    "all_model_types = [\n",
    "    TrajectoryPredictor,\n",
    "    BiLSTMPredictor,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集：验证集：测试集 == 6:2:2\n",
    "def split_dataset(df, features, window_size):\n",
    "    seq, label = createSequence(df, features, window_size)\n",
    "\n",
    "    # train\n",
    "    train_seq, test_seq = train_test_split(seq, test_size=0.4, random_state=seed)\n",
    "    train_label, test_label = train_test_split(label, test_size=0.4, random_state=seed)\n",
    "\n",
    "    # val & test\n",
    "    val_seq, test_seq = train_test_split(test_seq, test_size=0.5, random_state=seed)\n",
    "    val_label, test_label = train_test_split(test_label, test_size=0.5, random_state=seed)\n",
    "\n",
    "    return train_seq, train_label, val_seq, val_label, test_seq, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 15\n",
    "lr = 1e-2\n",
    "epoch_num = 200\n",
    "logging_steps = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试多种模型与特征\n",
    "best_model = None\n",
    "best_features = []\n",
    "min_rmse = 1e+5\n",
    "\n",
    "df = pd.read_csv('./product_data/task4_train_data.csv')\n",
    "# 遍历特征\n",
    "for features in all_features:\n",
    "    train_seq, train_label, val_seq, val_label, test_seq, test_label = split_dataset(df, features, window_size)\n",
    "    # 遍历模型\n",
    "    for i in range(len(all_model_types)):\n",
    "        if i == 0:\n",
    "            model = BertPredictor(bert_model, output_dim=2)\n",
    "        elif i == 1:\n",
    "            model = BiLSTMPredictor(train_seq.shape[2], 108, train_label.shape[1]).to(device)\n",
    "        \n",
    "        print(f'current features: {features}', flush=True)\n",
    "        print(f'current model_type: {type(model)}', flush=True)\n",
    "\n",
    "\n",
    "        model, loss, rmse = trainModel(train_seq, train_label, val_seq, val_label, model, lr, epoch_num, logging_steps)\n",
    "        # 在（划分的）测试集上测试\n",
    "        predictions = []\n",
    "        test_set = TensorDataset(test_seq, test_label)\n",
    "        test_loader = DataLoader(\n",
    "            test_set, batch_size=32, shuffle=False, generator=torch.Generator(device=device))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                outputs = model(inputs)\n",
    "                predictions.append(outputs)\n",
    "\n",
    "        predictions = torch.cat(predictions, dim=0)\n",
    "        test_rmse = calc_rmse(predictions, test_label)\n",
    "        print(f'test rmse: {test_rmse:.5f}')\n",
    "        print(f'=' * 80, end='\\n\\n', flush=True)\n",
    "\n",
    "        # 记录最好的模型\n",
    "        if test_rmse < min_rmse:\n",
    "            min_rmse = test_rmse\n",
    "            best_model = model\n",
    "            best_features = features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
